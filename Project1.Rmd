---
title: "2024 College Basketball Analysis"
output:
  flexdashboard::flex_dashboard:
    orientation: columns  # Adjust orientation as needed
    theme: spacelab
    fontsize: 12pt
    
---


<style type="text/css">

li {font-size: 20px;}
.chart-title {  /* chart_title  */
   font-size: 18px;
   font-family: Algerian;
   
.highcharts-container { /* Change font size of content within Highcharts */
    font-size: 12px; /* Adjust the font size as needed */
  }
</style>

```{r setup, include=FALSE}
library(flexdashboard)
# This is the setup chunk
#  Here you can set global options for the entire document

library(knitr) # I recommend doing this here
library(rvest)
library(dplyr)
library(tidyr)
library(tm)
library(car)
library(lmtest)
library(GGally)
library(MASS)
library(leaps)


```




```{r, include=FALSE}

link = "https://kenpom.com/"
page = read_html(link)
table = page %>% html_nodes("table#ratings-table") %>%
  html_table() %>% .[[1]]
cbb_df = data.frame(table)

data = read.csv("CBBData.csv")
cbb_df2 = data.frame(data)
cbb_df2$NCAA_Tourney <- ifelse(grepl("NCAA", cbb_df2$School), "Yes", "No")
cbb_df2$School = gsub(" NCAA", "", cbb_df2$School)

names(cbb_df2)[names(cbb_df2) == "W.L."] = "Win_Loss_Percentage"
names(cbb_df2)[names(cbb_df2) == "W.1"] = "Conference Wins"
names(cbb_df2)[names(cbb_df2) == "L.1"] = "Conference Losses"
names(cbb_df2)[names(cbb_df2) == "W.2"] = "Home_W"
names(cbb_df2)[names(cbb_df2) == "L.2"] = "Home_L"
names(cbb_df2)[names(cbb_df2) == "W.3"] = "Away_W"
names(cbb_df2)[names(cbb_df2) == "L.3"] = "Away_L"
names(cbb_df2)[names(cbb_df2) == "Tm."] = "Points_For"
names(cbb_df2)[names(cbb_df2) == "Opp."] = "Points_Against"
names(cbb_df2)[names(cbb_df2) == "FG."] = "FG_Perecntage"
names(cbb_df2)[names(cbb_df2) == "X3P"] = "3P"
names(cbb_df2)[names(cbb_df2) == "X3PA"] = "3PA"
names(cbb_df2)[names(cbb_df2) == "X3P."] = "3P_Percentage"
names(cbb_df2)[names(cbb_df2) == "FT."] = "FT_Percentage"
ready_to_merge = cbb_df2[-c(1,3,4,5,7,8)]

ready_to_merge$`Conference Wins` = as.numeric(ready_to_merge$`Conference Wins`)
ready_to_merge$`Conference Losses` = as.numeric(ready_to_merge$`Conference Losses`)
ready_to_merge$Home_W = as.numeric(ready_to_merge$Home_W)
ready_to_merge$Home_L = as.numeric(ready_to_merge$Home_L)
ready_to_merge$Away_W = as.numeric(ready_to_merge$Away_W)
ready_to_merge$Away_L = as.numeric(ready_to_merge$Away_L)
ready_to_merge$Points_For = as.numeric(ready_to_merge$Points_For)
ready_to_merge$Points_Against = as.numeric(ready_to_merge$Points_Against)
ready_to_merge$MP = as.numeric(ready_to_merge$MP)
ready_to_merge$FG = as.numeric(ready_to_merge$FG)
ready_to_merge$FGA = as.numeric(ready_to_merge$FGA)
ready_to_merge$FG_Perecntage = as.numeric(ready_to_merge$FG_Perecntage)
ready_to_merge$`3P` = as.numeric(ready_to_merge$`3P`)
ready_to_merge$`3P_Percentage` = as.numeric(ready_to_merge$`3P_Percentage`)
ready_to_merge$FT = as.numeric(ready_to_merge$FT)
ready_to_merge$FTA = as.numeric(ready_to_merge$FTA)
ready_to_merge$FT_Percentage = as.numeric(ready_to_merge$FT_Percentage)
ready_to_merge$ORB = as.numeric(ready_to_merge$ORB)
ready_to_merge$TRB = as.numeric(ready_to_merge$TRB)
ready_to_merge$AST = as.numeric(ready_to_merge$AST)
ready_to_merge$STL = as.numeric(ready_to_merge$STL)
ready_to_merge$BLK = as.numeric(ready_to_merge$BLK)
ready_to_merge$TOV = as.numeric(ready_to_merge$TOV)
ready_to_merge$PF = as.numeric(ready_to_merge$PF)
ready_to_merge$NCAA_Tourney = as.factor(ready_to_merge$NCAA_Tourney)

new_column_names = cbb_df[1, ]
names(cbb_df) = new_column_names
cbb_df = cbb_df[-1, ]

cbb_df = cbb_df[-c(7,9,11,13,15,17,19,21)]
rownames(cbb_df) = NULL
cbb_df = cbb_df[-c(41,42,83,84,125,126,167,168,209,210,251,252,293,294,335,336,377,378), ]
rownames(cbb_df) = cbb_df$Rk

cbb_df = separate(cbb_df, "W-L", into = c("Wins", "Losses"), sep = "-")

cbb_df$Rk = as.numeric(cbb_df$Rk)
cbb_df$Team = removeNumbers(cbb_df$Team)
cbb_df$Wins = as.numeric(cbb_df$Wins)
cbb_df$Losses = as.numeric(cbb_df$Losses)
cbb_df$AdjEM = as.numeric(gsub("\\+", "", cbb_df$AdjEM))
cbb_df$AdjO = as.numeric(cbb_df$AdjO)
cbb_df$AdjD = as.numeric(cbb_df$AdjD)
cbb_df$AdjT = as.numeric(cbb_df$AdjT)
cbb_df$Luck = as.numeric(gsub("\\+", "", cbb_df$Luck))
cbb_df$AdjEM.1 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.1))
cbb_df$OppO = as.numeric(cbb_df$OppO)
cbb_df$OppD = as.numeric(cbb_df$OppD)
cbb_df$AdjEM.2 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.2))

names(cbb_df)[names(cbb_df) == "AdjEM"] = "EM"
names(cbb_df)[names(cbb_df) == "AdjO"] = "OE"
names(cbb_df)[names(cbb_df) == "AdjD"] = "DE"
names(cbb_df)[names(cbb_df) == "AdjT"] = "Tempo"
names(cbb_df)[names(cbb_df) == "AdjEM.1"] = "SOS"
names(cbb_df)[names(cbb_df) == "AdjEM.2"] = "NCSOS"
cbb_df$Team = trimws(cbb_df$Team)
ready_to_merge$School = trimws(ready_to_merge$School)
cbb_df$Team = gsub(" St\\.$", " State", cbb_df$Team)
ready_to_merge$School = gsub("-", " ", ready_to_merge$School)
ready_to_merge$School = gsub("Brigham Young", "BYU", ready_to_merge$School)
ready_to_merge$School = gsub("NC State", "N.C. State", ready_to_merge$School)
ready_to_merge$School = gsub("Southern Methodist", "SMU", ready_to_merge$School)
ready_to_merge$School = gsub("Nevada Las Vegas", "UNLV", ready_to_merge$School)
ready_to_merge$School = gsub("Virginia Commonwealth", "VCU", ready_to_merge$School)
ready_to_merge$School = gsub("Southern California", "USC", ready_to_merge$School)
ready_to_merge$School = gsub("Loyola", "Loyola Chicago", ready_to_merge$School)
ready_to_merge$School = gsub("Louisiana State", "LSU", ready_to_merge$School)
ready_to_merge$School = gsub("College of Charleston", "Charleston", ready_to_merge$School)
ready_to_merge$School = gsub("Sam Houston", "Sam Houston State", ready_to_merge$School)
ready_to_merge$School = gsub("Massachusetts Lowell", "UMass Lowell", ready_to_merge$School)
ready_to_merge$School = gsub("Texas A&M Corpus Christi", "Texas A&M Corpus Chris", ready_to_merge$School)
ready_to_merge$School = gsub("California Baptist", "Cal Baptist", ready_to_merge$School)
ready_to_merge$School = gsub("Pennsylvania", "Penn", ready_to_merge$School)
ready_to_merge$School = gsub("Kansas City", "UMKC", ready_to_merge$School)
ready_to_merge$School = gsub("Bowling Green State", "Bowling Green", ready_to_merge$School)
ready_to_merge$School = gsub("Southern Mississippi", "Southern Miss", ready_to_merge$School)
ready_to_merge$School = gsub("Grambling", "Grambling State", ready_to_merge$School)
ready_to_merge$School = gsub("Omaha", "Nebraska Omaha", ready_to_merge$School)
ready_to_merge$School = gsub("Central Connecticut State", "Central Connecticut", ready_to_merge$School)
ready_to_merge$School = gsub("Maryland Baltimore County", "UMBC", ready_to_merge$School)
ready_to_merge$School = gsub("Florida International", "FIU", ready_to_merge$School)
ready_to_merge$School = gsub("South Carolina Upstate", "USC Upstate", ready_to_merge$School)
ready_to_merge$School = gsub("FDU", "Fairleigh Dickinson", ready_to_merge$School)
ready_to_merge$School = gsub("Texas Rio Grande Valley", "UT Rio Grande Valley", ready_to_merge$School)
ready_to_merge$School = gsub("Prairie View", "Prairie View A&M", ready_to_merge$School)
ready_to_merge$School = gsub("Long Island University", "LIU", ready_to_merge$School)
ready_to_merge$School = gsub("Cal State Northridge", "Cal St. Northridge", ready_to_merge$School)
ready_to_merge$School = gsub("Cal State Fullerton", "Cal St. Fullerton", ready_to_merge$School)
ready_to_merge$School = gsub("Cal State Bakersfield", "Cal St. Bakersfield", ready_to_merge$School)
ready_to_merge$School = gsub("Loyola Chicago Marymount", "Loyola Marymount", ready_to_merge$School)
ready_to_merge$School = gsub("\\s*\\(([^\\)]+)\\)", " \\1", ready_to_merge$School)
ready_to_merge$School = gsub("Saint Mary's CA", "Saint Mary's", ready_to_merge$School)
ready_to_merge$School = gsub("St. John's NY", "St. John's", ready_to_merge$School)
ready_to_merge$School = gsub("Loyola Chicago IL", "Loyola Chicago", ready_to_merge$School)
ready_to_merge$School = gsub("Albany NY", "Albany", ready_to_merge$School)
ready_to_merge$School = gsub("Queens NC", "Queens", ready_to_merge$School)
ready_to_merge$School = gsub("Saint Francis PA", "Saint Francis", ready_to_merge$School)
ready_to_merge$School = gsub("Loyola Chicago MD", "Loyola MD", ready_to_merge$School)

merged_df = merge(cbb_df, ready_to_merge, by.x = "Team", by.y = "School", all.x = TRUE)
merged_df = merged_df[order(merged_df$Rk), ]
rownames(merged_df) = merged_df$Rk
merged_df[295, ]$`Conference Wins` = merged_df[295, ]$Wins
merged_df[295, ]$`Conference Losses` = merged_df[295, ]$Losses

```


# MLR

Column {data-width=650}
-----------------------------------------------------------------------

### Fitting a MLR 

```{r}
## Full Model with all variables
power_5 = c("ACC", "Big 12", "Big Ten", "Pac-12", "SEC")
predictive_data = cbb_df %>% filter(Conf %in% power_5)
head(predictive_data)
predictive_data = predictive_data[ ,-c(2,3)]

full_mdl = lm(Wins ~ ., data = predictive_data)
summary(full_mdl)
vif(full_mdl)

## Reduced model to eliminate multicollinearity
reduced_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(reduced_mdl)
vif(reduced_mdl)
avPlots(reduced_mdl)

## Assumptions
student_r = rstudent(reduced_mdl)
fitted_values = reduced_mdl$fitted.values

plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(reduced_mdl)

qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)

## Outliers
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals', main = 'Student vs Fitted')
abline(0,0, col = 'blue')
abline(h = c(-2,2), col= 'red')

h = hatvalues(reduced_mdl)
plot(h, main = 'Leverage Plots', ylab = 'Leverage Values', xlab = 'Observation Index')
p = 4; n = length(predictive_data[,1])
cutoff = (2*p)/n
abline(h = cutoff, col = 'black')

cd = cooks.distance(reduced_mdl)
plot(cd, ylab = 'Cooks Distance', xlab = 'Observation Index', main = 'Cooks Distance Plot')
abline(h = 0.1, col = 'black')
predictive_data[which(cd > 0.6), ]
cbb_df[43, ]
```

Column {data-width=350}
-----------------------------------------------------------------------

### Exhaustive Model Approach

```{r}
regit.full = regsubsets(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data, method = 'exhaustive', nbest = 1)
output = summary(regit.full, all.best = TRUE)
criterion_mat = cbind(output$rsq, output$adjr2, output$cp, output$bic)
colnames(criterion_mat) = c('R2', 'AdjR2', 'Cp', 'BIC')
results_mat = cbind(output$outmat, round(criterion_mat, 3))
results_mat
```

### Analyzing what was found to be the best model

```{r}
best_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppD + NCSOS, data = predictive_data)
summary(best_mdl)
vif(best_mdl)
avPlots(best_mdl)

## Assumptions
student_r = rstudent(best_mdl)
fitted_values = best_mdl$fitted.values

plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(best_mdl)

qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
```


# Ridge regression



Column {data-width=650}
-----------------------------------------------------------------------

### Chart A

Ridge regression is a regularization technique(Method in statistics used to reduce error caused by overfitting of data) for linear regression models. Used to get rid of overfitting in training data we use for our model. It is also know as L2 regularization. Problem that is solved using this regression is "Multicollinearity". In this technique of regilarization we add a bias into the model for decreasing model's variance. 

Residual Sum Squares formula for linear regression is given by \ \
$RSS = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$ \
\
Where: \
n is the number of data points in the dataset. \
$y_i$ is the observed value of the dependent variable for data point \
$\hat{y}_i$ is the predicted value of the dependent variable for data point i based on the regression model. \ \
Where as by adding the regularization term according to Ridge regression we would get \ \
$RSS_{ridge} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p} \beta_j^2$
$\lambda$ is the regularization parameter (also known as the ridge parameter or penalty parameter) that controls the strength of the regularization.} \
$p$ is the number of predictor variables (features) in the regression model.\
$\beta_j$ represents the coefficients (weights) associated with each predictor variable. \


```{r}
# Load the necessary libraries
library(glmnet)
library(dplyr)
library(plotly)  # for 3D plots
 
# Split the data into predictors (X) and response variable (y)
X <- as.matrix(cbb_df[, c("OE", "SOS")])
y <- cbb_df$Wins

# Split the data into training and testing sets (e.g., 70% training, 30% testing)
set.seed(123)  # for reproducibility
train_indices <- sample(nrow(cbb_df), 0.7 * nrow(cbb_df))
X_train <- X[train_indices, ]
y_train <- y[train_indices]
X_test <- X[-train_indices, ]
y_test <- y[-train_indices]



ridge_model <- cv.glmnet(x = X_train, y = y_train, alpha = 0)  # alpha = 0 for ridge regression

# Get the optimal lambda value chosen by cross-validation
optimal_lambda <- ridge_model$lambda.min  # You can also use `lambda.1se` for a more regularized model

# Extract the coefficients for the optimal lambda value
coefficients_ridge <- coef(ridge_model, s = optimal_lambda)

# Form the equation of the ridge regression model
intercept <- coefficients_ridge[1]
coefficients <- coefficients_ridge[-1]  # Exclude the intercept term
features <- colnames(X_train)
ridge_equation <- paste("y =", paste(coefficients, features, sep = " * ", collapse = " + "), "+", intercept)

# Print the equation
print(ridge_equation)

# Define the plane equation coefficients
intercept <- -61.7454572
coef_OE <- 0.7459537
coef_SOS <- -0.2537968

# Define a function for the plane equation
plane_equation <- function(x, y) {
  return(intercept + coef_OE * x + coef_SOS * y)
}

# Calculate predicted wins using the plane equation
predicted_wins <- plane_equation(X_train[,"OE"], X_train[,"SOS"])

# Create a grid of points for the plane
grid_points <- expand.grid(OE = seq(min(X_train[,"OE"]), max(X_train[,"OE"]), length.out = 50),
                            SOS = seq(min(X_train[,"SOS"]), max(X_train[,"SOS"]), length.out = 50))
grid_points$Wins <- plane_equation(grid_points$OE, grid_points$SOS)

# Create the 3D scatter plot with plotly
ridge.plot <- plot_ly(x = X_train[,"OE"], y = X_train[,"SOS"], z = y_train, 
                      type = "scatter3d", mode = "markers", 
                      marker = list(color = "blue", size = 5)) %>%
  layout(title = "3D Scatter Plot of Training Data",
         scene = list(xaxis = list(title = "OE"), 
                      yaxis = list(title = "SOS"), 
                      zaxis = list(title = "Wins")),
         width = 800, height = 600)

# Add the plane using the grid points
ridge.plot <- add_surface(p = ridge.plot,
                          z = matrix(grid_points$Wins, 
                                      nrow = length(unique(grid_points$OE)), 
                                      ncol = length(unique(grid_points$SOS)), 
                                      byrow = TRUE),
                          x = unique(grid_points$OE),
                          y = unique(grid_points$SOS),
                          colorscale = "Viridis")

ridge.plot
```




Column {data-width=350}
-----------------------------------------------------------------------

### Making predictions using ridge model

```{r}

```
To obtain the equation of the ridge regression model, we first fitted the model using cross-validated ridge regression with the `cv.glmnet` function in R. This function selects an optimal lambda value through cross-validation. \

After fitting the ridge regression model, we extracted the coefficients corresponding to the optimal lambda value. The coefficients represent the weights assigned to each predictor variable in the model. \ 

The equation of the ridge regression model can be written as follows: \

\[ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n \] \

Where: \
- \( y \) is the dependent variable (e.g., Wins in our case). \
- \( \beta_0 \) is the intercept term. \
- \( \beta_1, \beta_2, \ldots, \beta_n \) are the coefficients corresponding to  predictor variables \( x_1, x_2, \ldots, x_n \) respectively. \

For our specific ridge regression model, the coefficients and variables are substituted into the equation to form the final equation, which can be written in the form: \

\[
\text{Wins} = -61.7454572 + 0.7459537 \times \text{OE} - 0.2537968 \times \text{SOS}
\]

### Chart C

```{r}
ridge_predictions <- predict(ridge_model, newx = X_test, s = optimal_lambda)

# Calculate Mean Squared Error (MSE)
mse_ridge <- mean((y_test - ridge_predictions)^2)

# Calculate R-squared (R2)
rsquared_ridge <- 1 - (sum((y_test - ridge_predictions)^2) / sum((y_test - mean(y_test))^2))

# Calculate Root Mean Squared Error (RMSE)
rmse_ridge <- sqrt(mse_ridge)

# Print the results
cat("Ridge Regression Model:\n")
cat("MSE:", mse_ridge, "\n")
cat("R-squared:", rsquared_ridge, "\n")
cat("RMSE:", rmse_ridge, "\n")
```


# KNN Classification

Column {data-width=450}
-----------------------------------------------------------------------

### Chart A

We are performing $\textbf{k-Nearest Neighbors (kNN)}$ classification on a dataset with predictors $\textbf{"SOS" (Strength of Schedule)}$ and $\textbf{"DE" (Defensive Efficiency)}$, $\textbf{"Tempo"}$ categorizing teams based on their win-loss percentages into four categories: $\textbf{“Successful", “Above Average", “Average,"}$ and $\textbf{“Below Average"}$. It splits the data into training and test sets, trains a kNN classifier with $\textbf{k=7}$ neighbors, and evaluates its accuracy, providing insights into team categorization based on performance metrics.


```{r}
library(class)
library(caret)
library(RColorBrewer)
merged_df$team_cat <- ifelse(merged_df$Win_Loss_Percentage > 0.75, "Successful",
                              ifelse(merged_df$Win_Loss_Percentage > 0.5, "Above Average",
                                     ifelse(merged_df$Win_Loss_Percentage > 0.25, "Average",
                                            "Below Average")))
set.seed(123)  # For reproducibility
indices <- sample(1:nrow(merged_df), size = 0.8 * nrow(merged_df), replace = FALSE)

# Create training and test datasets
train_data <- merged_df[indices, ]
test_data <- merged_df[-indices, ]

X_train <- as.data.frame(train_data[, c("SOS", "DE", "Tempo" )])
y_train <- train_data$team_cat
X_test <- as.data.frame(test_data[, c("SOS", "DE", "Tempo")])
y_test <- test_data$team_cat

knitr::kable(head(merged_df[,c("SOS", "DE", "Tempo", "team_cat")]))

# Create KNN classifier
k <- 7  # Number of neighbors
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Evaluate the model
accuracy <- mean(knn_model == y_test)
cat("Accuracy of KNN classifier:", accuracy, "\n")


```

#### PCA 

```{r}
pca_result <- prcomp(train_data[, c("SOS", "DE", "Tempo")], scale. = TRUE)

# Convert PCA results to a data frame
pca_df <- as.data.frame(pca_result$x)
pca_df$team_cat <- as.factor(y_train)
pca_df$Team <- train_data$Team  # Assuming "Team" column contains team names

# Create interactive PCA graph with plotly
pca_plot <- plot_ly(data = pca_df, x = ~PC1, y = ~PC2, color = ~team_cat, text = ~Team, type = "scatter", mode = "markers",
                    marker = list(size = 10, opacity = 0.8)) %>%
  layout(title = "Interactive PCA Graph of Features",
         xaxis = list(title = "Principal Component 1"),
         yaxis = list(title = "Principal Component 2"),
         showlegend = TRUE,
         hoverlabel = list(bgcolor = "white"))

# Show the interactive PCA graph
pca_plot

```

The above graph is obtained after performing Principal Component Analysis (PCA) on the $\textbf{SOS}$, $\textbf{DE}$, and $\textbf{Tempo}$ variables from the $\textbf{train_data}$. It converts the PCA results into a data frame and creates an interactive scatter plot using plotly, where each data point represents a team. The plot displays the teams in a two-dimensional space based on the first two principal components ($\textbf{PC1}$ and $\textbf{PC2}$), with color indicating the $\textbf{team_cat}$ variable (team category) and team names shown as hover text.


Column {data-width=350}
-----------------------------------------------------------------------

### K value vs Accuracies

#### Ploting Accuracy for various values of K

```{r}
k_values <- seq(1, 50, by = 1)

# Initialize a vector to store accuracies
accuracies <- numeric(length(k_values))

# Loop through each K value and train a KNN model
for (i in seq_along(k_values)) {
  knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k_values[i])
  accuracies[i] <- mean(knn_model == y_test)
}

# Create a data frame for plotting
accuracy_df <- data.frame(K = k_values, Accuracy = accuracies)

max_accuracy_index <- which.max(accuracy_df$Accuracy)

# Plot accuracies vs. K values with highlighted point
plot_ly(data = accuracy_df, x = ~K, y = ~Accuracy, type = "scatter", mode = "lines+markers") %>%
  add_markers(data = accuracy_df[max_accuracy_index, ], color = I("red"), size = 3) %>%
  layout(title = "Accuracies vs. K Values",
         xaxis = list(title = "K Value"),
         yaxis = list(title = "Accuracy"),
         hoverlabel = list(bgcolor = "white"))

```




Above plot is a comprehensive evaluation of KNN models with varying numbers of neighbors (K) ranging from 1 to 50. It calculates the accuracy of each KNN model by comparing its predictions on the test dataset against the actual labels.We identify the K value that achieves the highest accuracy and highlights this optimal point in the plot using a distinctive red color


### Chart C


