summary(boxcox_mdl)
## Assumptions
student_r = rstudent(boxcox_mdl)
fitted_values = boxcox_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(boxcox_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
link = "https://kenpom.com/"
page = read_html(link)
table = page %>% html_nodes("table#ratings-table") %>%
html_table() %>% .[[1]]
cbb_df = data.frame(table)
new_column_names = cbb_df[1, ]
names(cbb_df) = new_column_names
cbb_df = cbb_df[-1, ]
cbb_df = cbb_df[-c(7,9,11,13,15,17,19,21)]
rownames(cbb_df) = NULL
cbb_df = cbb_df[-c(41,42,83,84,125,126,167,168,209,210,251,252,293,294,335,336,377,378), ]
rownames(cbb_df) = cbb_df$Rk
cbb_df = separate(cbb_df, "W-L", into = c("Wins", "Losses"), sep = "-")
cbb_df$Rk = as.numeric(cbb_df$Rk)
cbb_df$Team = removeNumbers(cbb_df$Team)
cbb_df$Wins = as.numeric(cbb_df$Wins)
cbb_df$Losses = as.numeric(cbb_df$Losses)
cbb_df$AdjEM = as.numeric(gsub("\\+", "", cbb_df$AdjEM))
cbb_df$AdjO = as.numeric(cbb_df$AdjO)
cbb_df$AdjD = as.numeric(cbb_df$AdjD)
cbb_df$AdjT = as.numeric(cbb_df$AdjT)
cbb_df$Luck = as.numeric(gsub("\\+", "", cbb_df$Luck))
cbb_df$AdjEM.1 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.1))
cbb_df$OppO = as.numeric(cbb_df$OppO)
cbb_df$OppD = as.numeric(cbb_df$OppD)
cbb_df$AdjEM.2 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.2))
names(cbb_df)[names(cbb_df) == "AdjEM"] = "EM"
names(cbb_df)[names(cbb_df) == "AdjO"] = "OE"
names(cbb_df)[names(cbb_df) == "AdjD"] = "DE"
names(cbb_df)[names(cbb_df) == "AdjT"] = "Tempo"
names(cbb_df)[names(cbb_df) == "AdjEM.1"] = "SOS"
names(cbb_df)[names(cbb_df) == "AdjEM.2"] = "NCSOS"
## Full Model with all variables
predictive_data = cbb_df[ ,-c(2,3)]
full_mdl = lm(Wins ~ ., data = predictive_data)
summary(full_mdl)
vif(full_mdl)
## Reduced model to eliminate multicollinearity
reduced_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(reduced_mdl)
vif(reduced_mdl)
avPlots(reduced_mdl)
## Assumptions
student_r = rstudent(reduced_mdl)
fitted_values = reduced_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(reduced_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
## Outliers
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals', main = 'Student vs Fitted')
abline(0,0, col = 'blue')
abline(h = c(-2,2), col= 'red')
h = hatvalues(reduced_mdl)
plot(h, main = 'Leverage Plots', ylab = 'Leverage Values', xlab = 'Observation Index')
p = 4; n = length(predictive_data[,1])
cutoff = (2*p)/n
abline(h = cutoff, col = 'black')
cd = cooks.distance(reduced_mdl)
plot(cd, ylab = 'Cooks Distance', xlab = 'Observation Index', main = 'Cooks Distance Plot')
abline(h = 0.1, col = 'black')
ggpairs(predictive_data, columns = c("Wins", "EM", "Tempo", "Luck", "SOS", "NCSOS"),
upper = list(continuous = "smooth"), lower = list(continuous = "cor"))
ggpairs(predictive_data, columns = c("Wins", "EM", "Tempo", "Luck", "SOS", "NCSOS"),
upper = list(continuous = "smooth"), lower = list(continuous = "cor"))
## Applying a Transformation
```{r}
## Assumptions
student_r = rstudent(boxcox_mdl)
fitted_values = boxcox_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(boxcox_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
bc_results = boxcox(reduced_mdl)
optimal_lambda = bc_results$x[which.max(bc_results$y)]
predictive_data$Wins_Transform = (predictive_data$Wins)^optimal_lambda
boxcox_mdl = lm(Wins_Transform ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(boxcox_mdl)
## Assumptions
student_r = rstudent(boxcox_mdl)
fitted_values = boxcox_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(boxcox_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
avPlots(boxcox_mdl)
# This is the setup chunk
#  Here you can set global options for the entire document
library(knitr) # I recommend doing this here
library(rvest)
library(dplyr)
library(tidyr)
library(tm)
library(car)
library(lmtest)
library(GGally)
library(MASS)
# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE,
comment = NA, # Required
fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
fig.align = "center",
fig.width = 7,
fig.height = 7,
message = FALSE, # Turn off load messages
warning = FALSE # Turn off warnings
)
# You should not echo this chunk.
# include=FALSE does more than echo=FALSE, it actually does: echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.show='hide'
# You should set your working directory at the very beginning of your R Markdown file
setwd("/Users/matthewhill/Documents/VT/Junior/CMDA 4654/Project 1/P1_CMDA4654")
# In linux ~/ is shorthand for /home/username/
# You should type things out properly for your system
# Mac: /Users/matthewhill/Documents/VT/Junior/CMDA 4654/
# Windows: C:/Users/username/Documents/etc/Lecture/Lecture_03/.../
link = "https://kenpom.com/"
page = read_html(link)
table = page %>% html_nodes("table#ratings-table") %>%
html_table() %>% .[[1]]
cbb_df = data.frame(table)
new_column_names = cbb_df[1, ]
names(cbb_df) = new_column_names
cbb_df = cbb_df[-1, ]
cbb_df = cbb_df[-c(7,9,11,13,15,17,19,21)]
rownames(cbb_df) = NULL
cbb_df = cbb_df[-c(41,42,83,84,125,126,167,168,209,210,251,252,293,294,335,336,377,378), ]
rownames(cbb_df) = cbb_df$Rk
cbb_df = separate(cbb_df, "W-L", into = c("Wins", "Losses"), sep = "-")
cbb_df$Rk = as.numeric(cbb_df$Rk)
cbb_df$Team = removeNumbers(cbb_df$Team)
cbb_df$Wins = as.numeric(cbb_df$Wins)
cbb_df$Losses = as.numeric(cbb_df$Losses)
cbb_df$AdjEM = as.numeric(gsub("\\+", "", cbb_df$AdjEM))
cbb_df$AdjO = as.numeric(cbb_df$AdjO)
cbb_df$AdjD = as.numeric(cbb_df$AdjD)
cbb_df$AdjT = as.numeric(cbb_df$AdjT)
cbb_df$Luck = as.numeric(gsub("\\+", "", cbb_df$Luck))
cbb_df$AdjEM.1 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.1))
cbb_df$OppO = as.numeric(cbb_df$OppO)
cbb_df$OppD = as.numeric(cbb_df$OppD)
cbb_df$AdjEM.2 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.2))
names(cbb_df)[names(cbb_df) == "AdjEM"] = "EM"
names(cbb_df)[names(cbb_df) == "AdjO"] = "OE"
names(cbb_df)[names(cbb_df) == "AdjD"] = "DE"
names(cbb_df)[names(cbb_df) == "AdjT"] = "Tempo"
names(cbb_df)[names(cbb_df) == "AdjEM.1"] = "SOS"
names(cbb_df)[names(cbb_df) == "AdjEM.2"] = "NCSOS"
## Full Model with all variables
predictive_data = cbb_df[ ,-c(2,3)]
full_mdl = lm(Wins ~ ., data = predictive_data)
summary(full_mdl)
vif(full_mdl)
## Reduced model to eliminate multicollinearity
reduced_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(reduced_mdl)
vif(reduced_mdl)
avPlots(reduced_mdl)
## Assumptions
student_r = rstudent(reduced_mdl)
fitted_values = reduced_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(reduced_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
## Outliers
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals', main = 'Student vs Fitted')
abline(0,0, col = 'blue')
abline(h = c(-2,2), col= 'red')
h = hatvalues(reduced_mdl)
plot(h, main = 'Leverage Plots', ylab = 'Leverage Values', xlab = 'Observation Index')
p = 4; n = length(predictive_data[,1])
cutoff = (2*p)/n
abline(h = cutoff, col = 'black')
cd = cooks.distance(reduced_mdl)
plot(cd, ylab = 'Cooks Distance', xlab = 'Observation Index', main = 'Cooks Distance Plot')
abline(h = 0.1, col = 'black')
ggpairs(predictive_data, columns = c("Wins", "EM", "Tempo", "Luck", "SOS", "NCSOS"),
upper = list(continuous = "smooth"), lower = list(continuous = "cor"))
bc_results = boxcox(reduced_mdl)
optimal_lambda = bc_results$x[which.max(bc_results$y)]
predictive_data$Wins_Transform = (predictive_data$Wins)^optimal_lambda
boxcox_mdl = lm(Wins_Transform ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(boxcox_mdl)
## Assumptions
student_r = rstudent(boxcox_mdl)
fitted_values = boxcox_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(boxcox_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
exercise = read.csv("C:/Users/surya/Downloads/merged_exercise_calories.csv")
exercise = read.csv("merged_exercise_calories.csv")
exercise <- exercise[-1]
head(exercise)
exercise$Gender <- as.factor(exercise$Gender)
ggplot(data = exercise, aes(x = Calories)) +
geom_histogram(binwidth = 50, color = "grey") +
theme_minimal() +
labs(title = "Histogram of Calories Burned", x = "Calories", y = "Frequency")
# Grouping people by age
exercise$AgeGroup <- cut(exercise$Age, breaks = c(0, 20, 30, 40, 50, 60, 70, Inf),
labels = c("0-20", "21-30", "31-40", "41-50", "51-60", "61-70", "71+"))
ggplot(data = exercise, aes(x = Gender, y = Calories, fill = AgeGroup)) +
geom_violin() +
scale_fill_brewer(palette = "Spectral") +
theme_minimal() +
labs(title = "Violin Plot of Calories Burned by Gender, Colored by Age Group", x = "Gender", y = "Calories")
columns <- names(exercise)
columns <- columns[columns != "Gender"]
# Calculate summary statistics
summary_table <- sapply(exercise[columns], function(x) {
c(Mean = mean(as.numeric(x)),
Median = median(as.numeric(x)),
SD = sd(as.numeric(x)),
Min = min(as.numeric(x)),
Max = max(as.numeric(x)))
})
# Print the summary table
print(summary_table)
nrow(exercise)
colnames(exercise)
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
mins = c("NA", min(exercise$Age), min(exercise$Height), min(exercise$Weight), min(exercise$Duration), min(exercise$Heart_Rate), min(exercise$Body_Temp), min(exercise$AgeGroup))
medians = c("NA", median(exercise$Age), median(exercise$Height), median(exercise$Weight), median(exercise$Duration), median(exercise$Heart_Rate), median(exercise$Body_Temp), median(exercise$AgeGroup))
means = c("NA", mean(exercise$Age), mean(exercise$Height), mean(exercise$Weight), mean(exercise$Duration), mean(exercise$Heart_Rate), mean(exercise$Body_Temp), mean(exercise$AgeGroup))
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
descriptions = c("Gender of Participant",
"Age of Participant",
"Height of Participant",
"Weight of Participant",
"Duration of Workout",
"Heart Rate of Particiapnt",
"Body Temp of Participant",
"Age Bracket of Participant")
explanatory_variables = data.frame(names, types, descriptions)
explanatory_variables = kable(explanatory_variables, col.names = c("Explanatory Varaible Name", "Data Type"), row.names = FALSE, align = "c", caption = "Explanatory Variables")
explanatory_variables
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
descriptions = c("Gender of Participant",
"Age of Participant",
"Height of Participant",
"Weight of Participant",
"Duration of Workout",
"Heart Rate of Particiapnt",
"Body Temp of Participant",
"Age Bracket of Participant")
explanatory_variables = data.frame(names, types, descriptions)
explanatory_variables = kable(explanatory_variables, col.names = c("Explanatory Varaible Name", "Data Type", "Description"), row.names = FALSE, align = "c", caption = "Explanatory Variables")
explanatory_variables
explanatory_variables
type = class(exercise$Calories)
type = class(exercise$Calories)
name = "Calories"
description = "Calories burned during workout"
response_variable = data.frame(name, type, description)
response_variable = kable(response_variable, col.names = c("Response Varaible Name", "Data Type", "Description"), row.names = FALSE, align = "c", caption = "Response Variable")
response_variable
duration
class(exercise$Duration)
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$Duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
descriptions = c("Gender of Participant",
"Age of Participant",
"Height of Participant",
"Weight of Participant",
"Duration of Workout",
"Heart Rate of Particiapnt",
"Body Temp of Participant",
"Age Bracket of Participant")
explanatory_variables = data.frame(names, types, descriptions)
explanatory_variables = kable(explanatory_variables, col.names = c("Explanatory Varaible Name", "Data Type", "Description"), row.names = FALSE, align = "c", caption = "Explanatory Variables")
explanatory_variables
type = class(exercise$Calories)
name = "Calories"
description = "Calories burned during workout"
response_variable = data.frame(name, type, description)
response_variable = kable(response_variable, col.names = c("Response Varaible Name", "Data Type", "Description"), row.names = FALSE, align = "c", caption = "Response Variable")
response_variable
explanatory_variables
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$Duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
mins = c("NA", min(exercise$Age), min(exercise$Height), min(exercise$Weight), min(exercise$Duration), min(exercise$Heart_Rate), min(exercise$Body_Temp), min(exercise$AgeGroup))
maxs = c("NA", max(exercise$Age), max(exercise$Height), max(exercise$Weight), max(exercise$Duration), max(exercise$Heart_Rate), max(exercise$Body_Temp), max(exercise$AgeGroup))
gender = class(exercise$Gender)
age = class(exercise$Age)
height = class(exercise$Height)
weight = class(exercise$Weight)
duration = class(exercise$Duration)
hr = class(exercise$Heart_Rate)
body_temp = class(exercise$Body_Temp)
age_grp = class(exercise$AgeGroup)
names = c("Gender", "Age", "Height", "Weight", "Duration", "Heart Rate", "Body Temp", "Age Group")
types = c(gender, age, height, weight, duration, hr, body_temp, age_grp)
mins = c("NA", min(exercise$Age), min(exercise$Height), min(exercise$Weight), min(exercise$Duration), min(exercise$Heart_Rate), min(exercise$Body_Temp), min(as.numeric(exercise$AgeGroup)))
maxs = c("NA", max(exercise$Age), max(exercise$Height), max(exercise$Weight), max(exercise$Duration), max(exercise$Heart_Rate), max(exercise$Body_Temp), max(as.numeric(exercise$AgeGroup)))
descriptions = c("Gender of Participant",
"Age of Participant",
"Height of Participant",
"Weight of Participant",
"Duration of Workout",
"Heart Rate of Particiapnt",
"Body Temp of Participant",
"Age Bracket of Participant")
explanatory_variables = data.frame(names, types, descriptions, mins, medians, means, maxs)
explanatory_variables = kable(explanatory_variables, col.names = c("Explanatory Varaible Name", "Data Type", "Description", "Min", "Max"), row.names = FALSE, align = "c", caption = "Explanatory Variables")
explanatory_variables = data.frame(names, types, descriptions, mins, maxs)
explanatory_variables = kable(explanatory_variables, col.names = c("Explanatory Varaible Name", "Data Type", "Description", "Min", "Max"), row.names = FALSE, align = "c", caption = "Explanatory Variables")
explanatory_variables
type = class(exercise$Calories)
name = "Calories"
min = min(exercise$Calories)
median = min(exercise$Calories)
mean = mean(exercise$Calories)
max = max(exercise$Calories)
description = "Calories burned during workout"
response_variable = data.frame(name, type, description, min, max)
response_variable = kable(response_variable, col.names = c("Response Varaible Name", "Data Type", "Description", "Min", "Max"), row.names = FALSE, align = "c", caption = "Response Variable")
response_variable
explanatory_variables
pairs(exercise, pch = 16, lower.panel = NULL)
# Exhaustive approach
regfit.full <- regsubsets(Calories ~ .-Weight-Duration, data = exercise,
method = 'exhaustive', nbest = 1)
# Model 1
full_mdl = lm(Calories ~ .-Weight-Duration, data = exercise)
summary(full_mdl)
# Checking for multicollinearlity
vif(mdl_opt)
View(cbb_df)
## Full Model with all variables
predictive_data = cbb_df[ ,-c(2,3)]
power_5 = c("ACC", "Big 12", "Big Ten", "Pac-12", "SEC")
predictive_data <- predictive_data %>% filter(Conf %in% power_5)
predictive_data
## Full Model with all variables
power_5 = c("ACC", "Big 12", "Big Ten", "Pac-12", "SEC")
predictive_data <- cbb_df %>% filter(Conf %in% power_5)
predictive_data = predictive_data[ ,-c(2,3)]
View(predictive_data)
## Full Model with all variables
power_5 = c("ACC", "Big 12", "Big Ten", "Pac-12", "SEC")
predictive_data = cbb_df %>% filter(Conf %in% power_5)
head(predictive_data)
predictive_data = predictive_data[ ,-c(2,3)]
full_mdl = lm(Wins ~ ., data = predictive_data)
summary(full_mdl)
vif(full_mdl)
## Reduced model to eliminate multicollinearity
reduced_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(reduced_mdl)
vif(reduced_mdl)
avPlots(reduced_mdl)
## Assumptions
student_r = rstudent(reduced_mdl)
fitted_values = reduced_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(reduced_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
## Outliers
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals', main = 'Student vs Fitted')
abline(0,0, col = 'blue')
abline(h = c(-2,2), col= 'red')
h = hatvalues(reduced_mdl)
plot(h, main = 'Leverage Plots', ylab = 'Leverage Values', xlab = 'Observation Index')
p = 4; n = length(predictive_data[,1])
cutoff = (2*p)/n
abline(h = cutoff, col = 'black')
cd = cooks.distance(reduced_mdl)
plot(cd, ylab = 'Cooks Distance', xlab = 'Observation Index', main = 'Cooks Distance Plot')
abline(h = 0.1, col = 'black')
predictive_data[which(cd > 0.6)]
predictive_data[which(cd > 0.6), ]
cbb_df[43, ]
regit.full = regsubsets(Wins ~ ., data = predictive_data, method = 'exhaustive', nbest = 2)
# This is the setup chunk
#  Here you can set global options for the entire document
library(knitr) # I recommend doing this here
library(rvest)
library(dplyr)
library(tidyr)
library(tm)
library(car)
library(lmtest)
library(GGally)
library(MASS)
# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE,
comment = NA, # Required
fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
fig.align = "center",
fig.width = 7,
fig.height = 7,
message = FALSE, # Turn off load messages
warning = FALSE # Turn off warnings
)
regit.full = regsubsets(Wins ~ ., data = predictive_data, method = 'exhaustive', nbest = 2)
library(leaps)
regit.full = regsubsets(Wins ~ ., data = predictive_data, method = 'exhaustive', nbest = 2)
output = summary(regit.full, all.best = TRUE)
criterion_mat = cbind(output$rsq, output$adjr2, output$cp, output$bic)
colnames(criterion_mat) = c('R2', 'AdjR2', 'Cp', 'BIC')
results_mat = cbind(output$outmat, round(criterion_mat, 3))
results_mat
regit.full = regsubsets(Wins ~ ., data = predictive_data, method = 'exhaustive', nbest = 1)
output = summary(regit.full, all.best = TRUE)
criterion_mat = cbind(output$rsq, output$adjr2, output$cp, output$bic)
colnames(criterion_mat) = c('R2', 'AdjR2', 'Cp', 'BIC')
results_mat = cbind(output$outmat, round(criterion_mat, 3))
results_mat
regit.full = regsubsets(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data, method = 'exhaustive', nbest = 1)
output = summary(regit.full, all.best = TRUE)
criterion_mat = cbind(output$rsq, output$adjr2, output$cp, output$bic)
colnames(criterion_mat) = c('R2', 'AdjR2', 'Cp', 'BIC')
results_mat = cbind(output$outmat, round(criterion_mat, 3))
results_mat
best_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppD + NCSOS, data = predictive_data)
summary(best_mdl)
vif(best_mdl)
avPlots(best_mdl)
best_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppD + NCSOS, data = predictive_data)
summary(best_mdl)
vif(best_mdl)
avPlots(best_mdl)
## Assumptions
student_r = rstudent(best_mdl)
fitted_values = best_mdl$fitted.values
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(best_mdl)
qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
