---
title: "CMDA-4654"
subtitle: "Project 1"
author: "Matthew Hill and Rohan Reddy Illapuram"
date: "April 1, 2024"
output:
  pdf_document:
    highlight: haddock
keep_tex: no
number_sections: no
html_document:
  df_print: paged
geometry: margin = 0.5in
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
documentclass: article
urlcolor: blue
---
  
<!-- The above is set to automatically compile to a .pdf file.   -->
<!-- It will only succeed if LaTeX is installed. -->
  
<!-- If you absolutely can't get LaTeX installed and/or working, then you can compile to a .html first,  -->
<!-- by clicking on the arrow button next to knit and selecting Knit to HTML. -->

<!-- You must then print you .html file to a .pdf by using first opening it in a web browser and then printing to a .pdf -->


```{r setup, include=FALSE}
# This is the setup chunk
#  Here you can set global options for the entire document

library(knitr) # I recommend doing this here
library(rvest)
library(dplyr)
library(tidyr)
library(tm)
library(car)
library(lmtest)
library(GGally)
library(MASS)
library(leaps)

# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, # Required
                      fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      message = FALSE, # Turn off load messages
                      warning = FALSE # Turn off warnings
                      )

```

\clearpage

```{r include=FALSE}
# You should not echo this chunk.
# include=FALSE does more than echo=FALSE, it actually does: echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.show='hide'

# You should set your working directory at the very beginning of your R Markdown file
setwd("/Users/matthewhill/Documents/VT/Junior/CMDA 4654/Project 1/P1_CMDA4654")

# In linux ~/ is shorthand for /home/username/
# You should type things out properly for your system
# Mac: /Users/matthewhill/Documents/VT/Junior/CMDA 4654/
# Windows: C:/Users/username/Documents/etc/Lecture/Lecture_03/.../


```

<!-- ---------------------------------------------------------------------------------------------------- -->
<!-- ---------------- Homework Problems start below these lines ----------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------- -->


### Web Scraping Data and Cleaning Data
```{r}
link = "https://kenpom.com/"
page = read_html(link)
table = page %>% html_nodes("table#ratings-table") %>%
  html_table() %>% .[[1]]
cbb_df = data.frame(table)

new_column_names = cbb_df[1, ]
names(cbb_df) = new_column_names
cbb_df = cbb_df[-1, ]

cbb_df = cbb_df[-c(7,9,11,13,15,17,19,21)]
rownames(cbb_df) = NULL
cbb_df = cbb_df[-c(41,42,83,84,125,126,167,168,209,210,251,252,293,294,335,336,377,378), ]
rownames(cbb_df) = cbb_df$Rk

cbb_df = separate(cbb_df, "W-L", into = c("Wins", "Losses"), sep = "-")

cbb_df$Rk = as.numeric(cbb_df$Rk)
cbb_df$Team = removeNumbers(cbb_df$Team)
cbb_df$Wins = as.numeric(cbb_df$Wins)
cbb_df$Losses = as.numeric(cbb_df$Losses)
cbb_df$AdjEM = as.numeric(gsub("\\+", "", cbb_df$AdjEM))
cbb_df$AdjO = as.numeric(cbb_df$AdjO)
cbb_df$AdjD = as.numeric(cbb_df$AdjD)
cbb_df$AdjT = as.numeric(cbb_df$AdjT)
cbb_df$Luck = as.numeric(gsub("\\+", "", cbb_df$Luck))
cbb_df$AdjEM.1 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.1))
cbb_df$OppO = as.numeric(cbb_df$OppO)
cbb_df$OppD = as.numeric(cbb_df$OppD)
cbb_df$AdjEM.2 = as.numeric(gsub("\\+", "", cbb_df$AdjEM.2))

names(cbb_df)[names(cbb_df) == "AdjEM"] = "EM"
names(cbb_df)[names(cbb_df) == "AdjO"] = "OE"
names(cbb_df)[names(cbb_df) == "AdjD"] = "DE"
names(cbb_df)[names(cbb_df) == "AdjT"] = "Tempo"
names(cbb_df)[names(cbb_df) == "AdjEM.1"] = "SOS"
names(cbb_df)[names(cbb_df) == "AdjEM.2"] = "NCSOS"
```

### Fitting a MLR 
```{r}
## Full Model with all variables
power_5 = c("ACC", "Big 12", "Big Ten", "Pac-12", "SEC")
predictive_data = cbb_df %>% filter(Conf %in% power_5)
head(predictive_data)
predictive_data = predictive_data[ ,-c(2,3)]

full_mdl = lm(Wins ~ ., data = predictive_data)
summary(full_mdl)
vif(full_mdl)

## Reduced model to eliminate multicollinearity
reduced_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data)
summary(reduced_mdl)
vif(reduced_mdl)
avPlots(reduced_mdl)

## Assumptions
student_r = rstudent(reduced_mdl)
fitted_values = reduced_mdl$fitted.values

plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(reduced_mdl)

qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)

## Outliers
plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals', main = 'Student vs Fitted')
abline(0,0, col = 'blue')
abline(h = c(-2,2), col= 'red')

h = hatvalues(reduced_mdl)
plot(h, main = 'Leverage Plots', ylab = 'Leverage Values', xlab = 'Observation Index')
p = 4; n = length(predictive_data[,1])
cutoff = (2*p)/n
abline(h = cutoff, col = 'black')

cd = cooks.distance(reduced_mdl)
plot(cd, ylab = 'Cooks Distance', xlab = 'Observation Index', main = 'Cooks Distance Plot')
abline(h = 0.1, col = 'black')
predictive_data[which(cd > 0.6), ]
cbb_df[43, ]
```

### Exhaustive Model Approach
```{r}
regit.full = regsubsets(Wins ~ OE + DE + Tempo + Luck + OppO + OppD + NCSOS, data = predictive_data, method = 'exhaustive', nbest = 1)
output = summary(regit.full, all.best = TRUE)
criterion_mat = cbind(output$rsq, output$adjr2, output$cp, output$bic)
colnames(criterion_mat) = c('R2', 'AdjR2', 'Cp', 'BIC')
results_mat = cbind(output$outmat, round(criterion_mat, 3))
results_mat
```

### Analyzing what was found to be the best model
```{r}
best_mdl = lm(Wins ~ OE + DE + Tempo + Luck + OppD + NCSOS, data = predictive_data)
summary(best_mdl)
vif(best_mdl)
avPlots(best_mdl)

## Assumptions
student_r = rstudent(best_mdl)
fitted_values = best_mdl$fitted.values

plot(fitted_values, student_r, xlab = 'Fitted Values', ylab = 'Studentized Residuals')
abline(0,0, col = 'blue')
bptest(best_mdl)

qqnorm(student_r)
abline(0,1,col='red')
hist(student_r)
shapiro.test(student_r)
```








